{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39395923",
   "metadata": {},
   "source": [
    "# read me\n",
    "\n",
    "相比example1做出的修改：\n",
    "\n",
    "\n",
    "1、解决了gp_x undefined问题 原因是全局变量的作用域只能是一个文件- -，解决措施就是把自定义和函数和gplearn主程序放在同一个文件中。\n",
    "\n",
    "2、对gplearn进行了修改\n",
    "\n",
    "\n",
    "   原版：用户指定每一代parent数目；返回公式数目；显示公式数目\n",
    "    \n",
    "    \n",
    "   新版：新增加了一个参数：candidate(candidate数目必须大于tournourment数目,小于parent),即每一代最终会返回candidate个候选者，计算这些候选者的相关性并排列，随机删除前(candidate - parent)组相关性较高因子中的一个，直至只剩余parent个因子,作为下一代的父代。这样做的目的是尽可能地消除共线性。\n",
    "   \n",
    "   X_train与y_train的划分方式进行了修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa92e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import gplearn\n",
    "import talib\n",
    "#from gp_extend_func import *\n",
    "from gplearn import genetic1\n",
    "from gplearn import genetic\n",
    "import gplearn\n",
    "from lib2to3.pgen2.pgen import DFAState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628ff3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protected_division(x1, x2):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n",
    "\n",
    "\n",
    "def protected_sqrt(x1):\n",
    "    return np.sqrt(np.abs(x1))\n",
    "\n",
    "\n",
    "def protected_log(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.where(np.abs(x1) > 0.001, np.log(np.abs(x1)), 0.)\n",
    "\n",
    "\n",
    "def protected_inverse(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.where(np.abs(x1) > 0.001, 1. / x1, 0.)\n",
    "\n",
    "\n",
    "def sigmoid(x1):\n",
    "    with np.errstate(over='ignore', under='ignore'):\n",
    "        return 1 / (1 + np.exp(-x1))\n",
    "\n",
    "\n",
    "# 相加\n",
    "def gp_add(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return np.add(data1, data2)\n",
    "\n",
    "\n",
    "# 相减\n",
    "def gp_sub(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return np.subtract(data1, data2)\n",
    "\n",
    "\n",
    "# 相乘\n",
    "def gp_mul(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return np.multiply(data1, data2)\n",
    "\n",
    "\n",
    "# 相除\n",
    "def gp_div(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return protected_division(data1, data2)\n",
    "\n",
    "\n",
    "# 两数比大小，取大值\n",
    "def gp_max(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return np.maximum(data1, data2)\n",
    "\n",
    "\n",
    "# 两数比大小，取小值\n",
    "def gp_min(data1, data2):\n",
    "    if isinstance(data1, float):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, float):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    if isinstance(data1, int):\n",
    "        data1 = np.repeat(data1, gp_x.shape[0])\n",
    "    if isinstance(data2, int):\n",
    "        data2 = np.repeat(data2, gp_x.shape[0])\n",
    "    return np.minimum(data1, data2)\n",
    "\n",
    "\n",
    "# 绝对值平方根\n",
    "def gp_sqrt(data):\n",
    "    if isinstance(data, float):\n",
    "        return protected_sqrt(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return protected_sqrt(np.repeat(data, gp_x.shape[0]))\n",
    "    return protected_sqrt(data)\n",
    "\n",
    "\n",
    "# 对数\n",
    "def gp_log(data):\n",
    "    if isinstance(data, float):\n",
    "        return protected_log(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return protected_log(np.repeat(data, gp_x.shape[0]))\n",
    "    return protected_log(data)\n",
    "\n",
    "\n",
    "# 取相反数\n",
    "def gp_neg(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.negative(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.negative(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.negative(data)\n",
    "\n",
    "\n",
    "# 近零的参数返回0\n",
    "def gp_inv(data):\n",
    "    if isinstance(data, float):\n",
    "        return protected_inverse(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return protected_inverse(np.repeat(data, gp_x.shape[0]))\n",
    "    return protected_inverse(data)\n",
    "\n",
    "\n",
    "# 取绝对值\n",
    "def gp_abs(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.abs(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.abs(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.abs(data)\n",
    "\n",
    "\n",
    "# 三角函数\n",
    "def gp_sin(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.sin(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.sin(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.sin(data)\n",
    "\n",
    "\n",
    "# 三角函数\n",
    "def gp_cos(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.cos(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.cos(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.cos(data)\n",
    "\n",
    "\n",
    "# 三角函数\n",
    "def gp_tan(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.tan(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.tan(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.tan(data)\n",
    "\n",
    "\n",
    "# 三角函数\n",
    "def gp_sig(data):\n",
    "    if isinstance(data, float):\n",
    "        return sigmoid(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return sigmoid(np.repeat(data, gp_x.shape[0]))\n",
    "    return sigmoid(data)\n",
    "\n",
    "\n",
    "def rolling_prod(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.prod(np.repeat(data, gp_x.shape[0]))\n",
    "    if isinstance(data, int):\n",
    "        return np.prod(np.repeat(data, gp_x.shape[0]))\n",
    "    return np.prod(data)\n",
    "\n",
    "\n",
    "# 数组10日移动窗口和\n",
    "def ts_sum(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).sum().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组的10日移动平均数\n",
    "def sma(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).mean().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口标准差\n",
    "def stddev(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口元素相乘\n",
    "def product(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(10).apply(rolling_prod).tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口最小值\n",
    "def ts_min(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).min().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口最小大值\n",
    "def ts_max(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = np.array(pd.Series(data.flatten()).rolling(window).max().tolist())\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组相邻两数差\n",
    "def delta(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    value = np.diff(data.flatten())\n",
    "    value = np.append(0, value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 往后移一个单位\n",
    "def delay(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    period = 1\n",
    "    value = pd.Series(data.flatten()).shift(1)\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口最大值索引\n",
    "def ts_argmax(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmax) + 1\n",
    "    value = np.nan_to_num(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# 数组10日移动窗口最小值索引\n",
    "def ts_argmin(data):\n",
    "    if isinstance(data, float):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    if isinstance(data, int):\n",
    "        return np.repeat(data, gp_x.shape[0])\n",
    "    window = 10\n",
    "    value = pd.Series(data.flatten()).rolling(10).apply(np.argmin) + 1\n",
    "    value = np.nan_to_num(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca1f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/example.csv')\n",
    "data['open_time'] = pd.to_datetime(data.open_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989725d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Factor import Factor\n",
    "data = Factor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d37104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_AD()\n",
    "data.get_ADX()\n",
    "data.get_APO()\n",
    "data.get_ATR()\n",
    "data.get_BOP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32032d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>pct</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>APO</th>\n",
       "      <th>ATR</th>\n",
       "      <th>BOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>8284.87</td>\n",
       "      <td>8286.05</td>\n",
       "      <td>8238.01</td>\n",
       "      <td>8242.33</td>\n",
       "      <td>219.186121</td>\n",
       "      <td>-0.005135</td>\n",
       "      <td>-179.765470</td>\n",
       "      <td>30.426678</td>\n",
       "      <td>17.244231</td>\n",
       "      <td>21.767857</td>\n",
       "      <td>-0.885512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 00:05:00</td>\n",
       "      <td>8241.55</td>\n",
       "      <td>8249.79</td>\n",
       "      <td>8230.03</td>\n",
       "      <td>8234.22</td>\n",
       "      <td>164.891499</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>-274.728286</td>\n",
       "      <td>30.426678</td>\n",
       "      <td>17.244231</td>\n",
       "      <td>21.767857</td>\n",
       "      <td>-0.370951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 00:10:00</td>\n",
       "      <td>8235.52</td>\n",
       "      <td>8245.07</td>\n",
       "      <td>8206.57</td>\n",
       "      <td>8243.39</td>\n",
       "      <td>175.031226</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-114.972513</td>\n",
       "      <td>30.426678</td>\n",
       "      <td>17.244231</td>\n",
       "      <td>21.767857</td>\n",
       "      <td>0.204416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 00:15:00</td>\n",
       "      <td>8242.94</td>\n",
       "      <td>8252.53</td>\n",
       "      <td>8235.18</td>\n",
       "      <td>8242.69</td>\n",
       "      <td>93.312935</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-127.503875</td>\n",
       "      <td>30.426678</td>\n",
       "      <td>17.244231</td>\n",
       "      <td>21.767857</td>\n",
       "      <td>-0.014409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 00:20:00</td>\n",
       "      <td>8239.17</td>\n",
       "      <td>8239.31</td>\n",
       "      <td>8210.01</td>\n",
       "      <td>8219.42</td>\n",
       "      <td>163.807780</td>\n",
       "      <td>-0.002397</td>\n",
       "      <td>-186.094508</td>\n",
       "      <td>30.426678</td>\n",
       "      <td>17.244231</td>\n",
       "      <td>21.767857</td>\n",
       "      <td>-0.674061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open_time     open     high      low    close      volume  \\\n",
       "0 2019-10-01 00:00:00  8284.87  8286.05  8238.01  8242.33  219.186121   \n",
       "1 2019-10-01 00:05:00  8241.55  8249.79  8230.03  8234.22  164.891499   \n",
       "2 2019-10-01 00:10:00  8235.52  8245.07  8206.57  8243.39  175.031226   \n",
       "3 2019-10-01 00:15:00  8242.94  8252.53  8235.18  8242.69   93.312935   \n",
       "4 2019-10-01 00:20:00  8239.17  8239.31  8210.01  8219.42  163.807780   \n",
       "\n",
       "        pct          AD        ADX        APO        ATR       BOP  \n",
       "0 -0.005135 -179.765470  30.426678  17.244231  21.767857 -0.885512  \n",
       "1 -0.000889 -274.728286  30.426678  17.244231  21.767857 -0.370951  \n",
       "2  0.000956 -114.972513  30.426678  17.244231  21.767857  0.204416  \n",
       "3 -0.000030 -127.503875  30.426678  17.244231  21.767857 -0.014409  \n",
       "4 -0.002397 -186.094508  30.426678  17.244231  21.767857 -0.674061  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.get_df()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e155fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pct'] = df.close.pct_change().fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdeb872",
   "metadata": {},
   "source": [
    "# genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9385061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定参数与candidate\n",
    "#进入循环\n",
    "#gen = 1 former = None else former = former\n",
    "#代与代之间：1 删除常值 2 按相关性随机剔除\n",
    "gp_add = gplearn.functions.make_function(function=gp_add, name='gp_add', arity=2)\n",
    "gp_sub = gplearn.functions.make_function(function=gp_sub, name='gp_sub', arity=2)\n",
    "gp_mul = gplearn.functions.make_function(function=gp_mul, name='gp_mul', arity=2)\n",
    "gp_div = gplearn.functions.make_function(function=gp_div, name='gp_div', arity=2)\n",
    "gp_max = gplearn.functions.make_function(function=gp_max, name='gp_max', arity=2)\n",
    "gp_min = gplearn.functions.make_function(function=gp_min, name='gp_min', arity=2)\n",
    "gp_sqrt = gplearn.functions.make_function(function=gp_sqrt, name='gp_sqrt', arity=1)\n",
    "gp_log = gplearn.functions.make_function(function=gp_log, name='gp_log', arity=1)\n",
    "gp_neg = gplearn.functions.make_function(function=gp_neg, name='gp_neg', arity=1)\n",
    "gp_inv = gplearn.functions.make_function(function=gp_inv, name='gp_inv', arity=1)\n",
    "gp_abs = gplearn.functions.make_function(function=gp_abs, name='gp_abs', arity=1)\n",
    "gp_sin = gplearn.functions.make_function(function=gp_sin, name='gp_sin', arity=1)\n",
    "gp_cos = gplearn.functions.make_function(function=gp_cos, name='gp_cos', arity=1)\n",
    "gp_tan = gplearn.functions.make_function(function=gp_tan, name='gp_tan', arity=1)\n",
    "gp_sig = gplearn.functions.make_function(function=gp_sig, name='gp_sig', arity=1)\n",
    "delta = gplearn.functions.make_function(function=delta, name='delta', arity=1)\n",
    "delay = gplearn.functions.make_function(function=delay, name='delay', arity=1)\n",
    "sma = gplearn.functions.make_function(function=sma, name='sma', arity=1)\n",
    "stddev = gplearn.functions.make_function(function=stddev, name='stddev', arity=1)\n",
    "product = gplearn.functions.make_function(function=product, name='product', arity=1)\n",
    "ts_min = gplearn.functions.make_function(function=ts_min, name='ts_min', arity=1)\n",
    "ts_max = gplearn.functions.make_function(function=ts_max, name='ts_max', arity=1)\n",
    "ts_argmax = gplearn.functions.make_function(function=ts_argmax, name='ts_argmax', arity=1)\n",
    "ts_argmin = gplearn.functions.make_function(function=ts_argmin, name='ts_argmin', arity=1)\n",
    "ts_sum = gplearn.functions.make_function(function=ts_sum, name='ts_sum', arity=1)\n",
    "\n",
    "\n",
    "init_function = [gp_add, gp_sub, gp_mul, gp_div, \n",
    "                 gp_sqrt, gp_log, gp_neg, gp_inv, \n",
    "                 gp_abs, gp_max, gp_min, gp_sin,\n",
    "                 gp_cos, gp_tan, gp_sig]\n",
    "user_function = [delta, delay,sma, stddev, product,ts_min, ts_max, ts_argmax, ts_argmin,ts_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd807014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得X与y\n",
    "origin_fator_lst = list(df.columns[7:])\n",
    "X = df[origin_fator_lst]\n",
    "y = df['pct'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4f19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得X_train 与 y_train;X_test与y_test\n",
    "train_ratio = 0.8\n",
    "X_train = X.iloc[:int(X.shape[0]*train_ratio)]\n",
    "y_train = y.iloc[:int(X.shape[0]*train_ratio)]\n",
    "X_test = X.iloc[int(X.shape[0]*train_ratio):-1]\n",
    "y_test = y.iloc[int(X.shape[0]*train_ratio):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "085fe0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_factor_choose(gp,candidate):\n",
    "    #计算新因子\n",
    "    new_factor_df = pd.DataFrame()\n",
    "    for g in gp[0]:\n",
    "        new_factor_df[str(g)]=eval(str(g))\n",
    "    valid_factor_lst = list(new_factor_df.columns)\n",
    "\n",
    "    #去除常数\n",
    "    for factor in new_factor_df.columns:\n",
    "        if (new_factor_df[factor].std() <1e-8):\n",
    "            valid_factor_lst.remove(factor)\n",
    "    corr_df = new_factor_df[valid_factor_lst].corr(method = 'spearman')\n",
    "\n",
    "    #相关性排序(绝对值)\n",
    "    re_dic = {}\n",
    "    for factor1_index in range(len(corr_df.index)):\n",
    "        for factor2_index in range(factor1_index,len(corr_df.columns)):\n",
    "            if factor1_index != factor2_index:\n",
    "                factor1 = corr_df.index[factor1_index]\n",
    "                factor2 = corr_df.columns[factor2_index]\n",
    "                key = tuple([factor1,factor2])\n",
    "                re_dic[key] = abs(corr_df.loc[factor1,factor2])\n",
    "\n",
    "    sort_lst = sorted(re_dic.keys())\n",
    "\n",
    "    #按照相关性进行删除\n",
    "    for i in range(len(sort_lst)):\n",
    "        tmp = sort_lst[-i]\n",
    "        rand = np.random.uniform(0,1,1)[0]\n",
    "        if rand < 1/2:\n",
    "            drop = tmp[0]\n",
    "        else:\n",
    "            drop = tmp[1]\n",
    "        try:\n",
    "            valid_factor_lst.remove(drop)\n",
    "        except:\n",
    "            pass\n",
    "        if len(valid_factor_lst) == candidate:\n",
    "            break\n",
    "    \n",
    "    #删除programs\n",
    "    program = gp[0]\n",
    "    program_candidate = []\n",
    "    for factor in valid_factor_lst:\n",
    "        program_candidate.append(program[list(new_factor_df.columns).index(factor)])\n",
    "    \n",
    "    return program_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d514c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gplearn\n",
    "generations = 3 #迭代的次数\n",
    "population_size = 20  #种群规模(每一代个体数目即初始树的个数)\n",
    "tournament_size = 10  #迭代一次进入下一次迭代数量\n",
    "hall_of_fame = 15 #备选数量\n",
    "candidate = 15\n",
    "n_components = 10#返回公式个数\n",
    "random_state=233 #锁随机子可以随便写个整数\n",
    "n_jobs = -1 #CPU核心个数.-1为全部核心\n",
    "function_set = init_function + user_function #迭代的公式\n",
    "init_method ='half and half'  #‘grow’公式和基础数据随机抽，'full'叶子抽基础数据，节点抽公式，‘half and half’ 前面两种各一半\n",
    "init_depth =(2,4)  #分枝的的深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6294c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60dca28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行第1代：\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    7.0s remaining:   21.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   44.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     5.60        0.0079708        9        0.0449239              N/A      0.00s\n"
     ]
    }
   ],
   "source": [
    "global gp_x\n",
    "import gc\n",
    "gp_x = X_train.values\n",
    "for factor in origin_fator_lst:\n",
    "    locals()[factor] = X_train[factor].to_numpy()\n",
    "for i in range(generations):\n",
    "    print(f'正在进行第{i+1}代：')\n",
    "    if i == 0:\n",
    "        gp0 = genetic1.SymbolicTransformer(\n",
    "                        feature_names= origin_fator_lst,           #基础行情数据的变量名\n",
    "                        function_set=function_set,          #迭代的函数公式\n",
    "                        generations=1,            #迭代的次数\n",
    "                        metric='spearman',                  #适应度的评价标准\n",
    "                        population_size=population_size,    #迭代的和序数\n",
    "                        tournament_size=tournament_size,                \n",
    "                        random_state=random_state,\n",
    "                        hall_of_fame = hall_of_fame,                   \n",
    "                        n_components = 1,\n",
    "                        n_jobs =n_jobs,\n",
    "                        init_method=init_method,\n",
    "                        init_depth = init_depth,\n",
    "                        verbose = 2,\n",
    "                        former = None\n",
    "                         )\n",
    "        gp0.fit(X_train, y_train)\n",
    "        former = gp0._programs\n",
    "        former[0] = new_factor_choose(former,candidate)\n",
    "        random_state += 1\n",
    "        del gp0\n",
    "        gc.collect()\n",
    "    elif i != (generations-1):\n",
    "        gp0 = genetic1.SymbolicTransformer(\n",
    "                        feature_names= origin_fator_lst,           #基础行情数据的变量名\n",
    "                        function_set=function_set,          #迭代的函数公式\n",
    "                        generations=1,            #迭代的次数\n",
    "                        metric='spearman',                  #适应度的评价标准\n",
    "                        population_size=population_size,    #迭代的和序数\n",
    "                        tournament_size=tournament_size,                \n",
    "                        random_state=random_state,\n",
    "                        hall_of_fame = hall_of_fame,                   \n",
    "                        n_components = 1,\n",
    "                        n_jobs =n_jobs,\n",
    "                        init_method=init_method,\n",
    "                        init_depth = init_depth,\n",
    "                        verbose = 2,\n",
    "                        former = former\n",
    "                         )\n",
    "        gp0.fit(X_train, y_train)\n",
    "        former = gp0._programs\n",
    "        former[0] = new_factor_choose(former,candidate)\n",
    "        random_state += 1\n",
    "        del gp0\n",
    "        gc.collect()\n",
    "    else:\n",
    "        gp0 = genetic1.SymbolicTransformer(\n",
    "                        feature_names= origin_fator_lst,           #基础行情数据的变量名\n",
    "                        function_set=function_set,          #迭代的函数公式\n",
    "                        generations=1,            #迭代的次数\n",
    "                        metric='spearman',                  #适应度的评价标准\n",
    "                        population_size=population_size,    #迭代的和序数\n",
    "                        tournament_size=tournament_size,                \n",
    "                        random_state=random_state,\n",
    "                        hall_of_fame = hall_of_fame,                   \n",
    "                        n_components = n_components,\n",
    "                        n_jobs =n_jobs,\n",
    "                        init_method=init_method,\n",
    "                        init_depth = init_depth,\n",
    "                        verbose = 2,\n",
    "                        former = former\n",
    "                         )\n",
    "        gp0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a0dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    9.5s remaining:   28.6s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   24.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     3.90        0.0156786        2        0.0635527              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>[gp_neg(ROC),\n",
       " gp_add(WMA, gp_min(gp_max(MOM, SAREXT), LINEARREG)),\n",
       " gp_abs(OBV),\n",
       " ts_min(ts_argmin(NATR)),\n",
       " gp_div(TRIX, KAMA)]</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SymbolicTransformer</label><div class=\"sk-toggleable__content\"><pre>[gp_neg(ROC),\n",
       " gp_add(WMA, gp_min(gp_max(MOM, SAREXT), LINEARREG)),\n",
       " gp_abs(OBV),\n",
       " ts_min(ts_argmin(NATR)),\n",
       " gp_div(TRIX, KAMA)]</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SymbolicTransformer(feature_names=['AD', 'ADOSC', 'ADX', 'ADXR', 'APO',\n",
       "                                   'aroondown', 'aroonup', 'AROONOSC', 'ATR',\n",
       "                                   'AVGPRICE', 'BBANDS_upper', 'BBANDS_middle',\n",
       "                                   'BBANDS_lower', 'BETA', 'BOP', 'CCI', 'CMO',\n",
       "                                   'CORREL', 'DEMA', 'DX', 'EMA', 'HT_DCPERIOD',\n",
       "                                   'HT_DCPHASE', 'HT_PHASOR_inphase',\n",
       "                                   'HT_PHASOR_quadrature', 'HT_SINE_sine',\n",
       "                                   'HT_SINE_leadsine', 'HT_TRENDMODE', 'KAMA',\n",
       "                                   'LINEARRE...\n",
       "                                  <gplearn.functions._Function object at 0x000001D6139A6B80>,\n",
       "                                  <gplearn.functions._Function object at 0x000001D6139A6670>,\n",
       "                                  <gplearn.functions._Function object at 0x000001D6139A6C10>,\n",
       "                                  <gplearn.functions._Function object at 0x000001D6139A68B0>],\n",
       "                    generations=1, hall_of_fame=20, init_depth=(2, 4),\n",
       "                    metric='spearman', n_components=5, n_jobs=-1,\n",
       "                    population_size=30, random_state=233, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "gp = genetic1.SymbolicTransformer(\n",
    "                        feature_names= origin_fator_lst,           #基础行情数据的变量名\n",
    "                        function_set=function_set,          #迭代的函数公式\n",
    "                        generations=1,            #迭代的次数\n",
    "                        metric='spearman',                  #适应度的评价标准\n",
    "                        population_size=population_size,    #迭代的和序数\n",
    "                        tournament_size=tournament_size,                \n",
    "                        random_state=random_state,\n",
    "                        hall_of_fame = 20,               \n",
    "                        n_components = 5,\n",
    "                        n_jobs =n_jobs,\n",
    "                        init_method=init_method,\n",
    "                        init_depth = init_depth,\n",
    "                        verbose = 2,\n",
    "                        former = None\n",
    "                         )\n",
    "gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d787f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这个放在外面\n",
    "global gp_x\n",
    "gp_x = X_train.values\n",
    "for factor in origin_fator_lst:\n",
    "    locals()[factor] = X_train[factor].to_numpy()\n",
    "\n",
    "candidate = 25   \n",
    "#计算新因子\n",
    "new_factor_df = pd.DataFrame()\n",
    "for g in gp._programs[0]:\n",
    "    new_factor_df[str(g)]=eval(str(g))\n",
    "valid_factor_lst = list(new_factor_df.columns)\n",
    "\n",
    "#去除常数\n",
    "for factor in new_factor_df.columns:\n",
    "    if (new_factor_df[factor].std() <1e-8):\n",
    "        valid_factor_lst.remove(factor)\n",
    "corr_df = new_factor_df[valid_factor_lst].corr(method = 'spearman')\n",
    "\n",
    "#相关性排序(绝对值)\n",
    "re_dic = {}\n",
    "for factor1_index in range(len(corr_df.index)):\n",
    "    for factor2_index in range(factor1_index,len(corr_df.columns)):\n",
    "        if factor1_index != factor2_index:\n",
    "            factor1 = corr_df.index[factor1_index]\n",
    "            factor2 = corr_df.columns[factor2_index]\n",
    "            key = tuple([factor1,factor2])\n",
    "            re_dic[key] = abs(corr_df.loc[factor1,factor2])\n",
    "            \n",
    "sort_lst = sorted(re_dic.keys())\n",
    "\n",
    "#按照相关性进行删除\n",
    "for i in range(len(sort_lst)):\n",
    "    tmp = sort_lst[-i]\n",
    "    rand = np.random.uniform(0,1,1)[0]\n",
    "    if rand < 1/2:\n",
    "        drop = tmp[0]\n",
    "    else:\n",
    "        drop = tmp[1]\n",
    "    try:\n",
    "        valid_factor_lst.remove(drop)\n",
    "    except:\n",
    "        pass\n",
    "    if len(valid_factor_lst) == candidate:\n",
    "        break\n",
    "len(valid_factor_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93eb71c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_factor_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf312b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = gp._programs[0]\n",
    "program_candidate = []\n",
    "for factor in valid_factor_lst:\n",
    "    program_candidate.append(program[list(new_factor_df.columns).index(factor)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa598d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(program_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ee98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
